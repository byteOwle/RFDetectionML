{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=cuda,floatX=float32\"\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D,Reshape,Input\n",
    "from tensorflow.keras.utils import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28x28 images of hand-written digits 0-9\n",
    "mnist = tf.keras.datasets.mnist \n",
    "\n",
    "image = mnist.load_data()\n",
    "filename = 'numbers_images.dat'\n",
    "\n",
    "fd = open(filename,'wb')\n",
    "pickle.dump( image, fd )\n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = open(filename, \"rb\")\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = normalize(x_train, axis=1)\n",
    "x_test = normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shpe = x_train.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Reshape(shpe+[1], input_shape=shpe))\n",
    "# model.add( Conv2D(256, (2,2)) ) \n",
    "model.add(Input(shpe))    # initial layer\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation=tf.nn.relu))    # initial layer\n",
    "# model.add(Dense(128, activation=tf.nn.relu))    # middle layer\n",
    "model.add(Dense(10, activation=tf.nn.softmax))  # output layer\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.6646 - accuracy: 0.8476 - val_loss: 0.3797 - val_accuracy: 0.8992\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3642 - accuracy: 0.8990 - val_loss: 0.3232 - val_accuracy: 0.9111\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3231 - accuracy: 0.9094 - val_loss: 0.3036 - val_accuracy: 0.9153\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3034 - accuracy: 0.9145 - val_loss: 0.2939 - val_accuracy: 0.9173\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2915 - accuracy: 0.9171 - val_loss: 0.2867 - val_accuracy: 0.9189\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2834 - accuracy: 0.9199 - val_loss: 0.2820 - val_accuracy: 0.9208\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2773 - accuracy: 0.9214 - val_loss: 0.2802 - val_accuracy: 0.9206\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2721 - accuracy: 0.9229 - val_loss: 0.2791 - val_accuracy: 0.9215\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2683 - accuracy: 0.9238 - val_loss: 0.2756 - val_accuracy: 0.9238\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2648 - accuracy: 0.9243 - val_loss: 0.2759 - val_accuracy: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f7b6ea8ac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9218\n",
      "0.2775522470474243 0.9218000173568726\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def prepare(path):\n",
    "    IMG_SIZE = 28\n",
    "    img_array = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    f_img = new_array.reshape(1, IMG_SIZE, IMG_SIZE)\n",
    "    return f_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying to import outside sources and use model for predictions\n",
    "# currently only works for sources from current data\n",
    "number = 'images/number_7.png'\n",
    "\n",
    "# print(x_test[0:1])\n",
    "# print(prepare(number))\n",
    "\n",
    "probs = model.predict(x_test[0:1])\n",
    "preds = np.argmax(probs, axis=1)\n",
    "# print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.3533539e-07 7.4869666e-11 5.2524265e-06 4.3860446e-03 5.3657558e-08\n",
      " 3.2702446e-06 3.5530561e-11 9.9541098e-01 5.0996755e-06 1.8858278e-04]  =>  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(probs[0], \" => \", preds[0])\n",
    "plt.imshow(x_test[0], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlepy36",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
